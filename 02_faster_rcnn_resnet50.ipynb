{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "import pdb\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "import transforms as T\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "\n",
    "from label_babel_dataset import LabelBabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDT2019-06-27T10:07:41-04:00\n",
      "\n",
      "CPython 3.7.3\n",
      "IPython 7.5.0\n",
      "\n",
      "torch 1.1.0\n",
      "torchvision 0.3.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -i -z -v -p torch,torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('.') / 'data'\n",
    "VAL_DIR = DATA_DIR / 'valid'\n",
    "TRN_DIR = DATA_DIR / 'train'\n",
    "MODEL_DIR = DATA_DIR / 'models'\n",
    "\n",
    "TRN_CSV = DATA_DIR / 'train.csv'\n",
    "VAL_CSV = DATA_DIR / 'valid.csv'\n",
    "\n",
    "BOX = 'box'\n",
    "CAT = 'category'\n",
    "PATH = 'path'\n",
    "CLASS = 'class'\n",
    "SUB_ID = 'subject_id'\n",
    "\n",
    "SEED = 23\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark = True  # Optimizes cudnn\n",
    "\n",
    "CATS = ['background', 'handwritten', 'typewritten']\n",
    "CLASSES = len(CATS)\n",
    "\n",
    "EPOCHS = 10  # 50\n",
    "CHECKPOINT = 'checkpoint_{}.pth.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>category</th>\n",
       "      <th>class</th>\n",
       "      <th>box</th>\n",
       "      <th>path</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2995300</td>\n",
       "      <td>typewritten</td>\n",
       "      <td>2</td>\n",
       "      <td>[231, 446, 368, 564]</td>\n",
       "      <td>data/train/2995300.jpg</td>\n",
       "      <td>data/images/2995300.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4128323</td>\n",
       "      <td>typewritten</td>\n",
       "      <td>2</td>\n",
       "      <td>[156, 322, 250, 382]</td>\n",
       "      <td>data/train/4128323.jpg</td>\n",
       "      <td>data/images/4128323.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4128517</td>\n",
       "      <td>handwritten</td>\n",
       "      <td>1</td>\n",
       "      <td>[155, 321, 248, 382]</td>\n",
       "      <td>data/train/4128517.jpg</td>\n",
       "      <td>data/images/4128517.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11783370</td>\n",
       "      <td>handwritten</td>\n",
       "      <td>1</td>\n",
       "      <td>[552, 1225, 966, 1483]</td>\n",
       "      <td>data/train/11783370.jpg</td>\n",
       "      <td>data/images/11783370.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11782469</td>\n",
       "      <td>typewritten</td>\n",
       "      <td>2</td>\n",
       "      <td>[612, 1182, 977, 1464]</td>\n",
       "      <td>data/train/11782469.jpg</td>\n",
       "      <td>data/images/11782469.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id     category  class                     box  \\\n",
       "0     2995300  typewritten      2    [231, 446, 368, 564]   \n",
       "1     4128323  typewritten      2    [156, 322, 250, 382]   \n",
       "2     4128517  handwritten      1    [155, 321, 248, 382]   \n",
       "3    11783370  handwritten      1  [552, 1225, 966, 1483]   \n",
       "4    11782469  typewritten      2  [612, 1182, 977, 1464]   \n",
       "\n",
       "                      path                  original  \n",
       "0   data/train/2995300.jpg   data/images/2995300.jpg  \n",
       "1   data/train/4128323.jpg   data/images/4128323.jpg  \n",
       "2   data/train/4128517.jpg   data/images/4128517.jpg  \n",
       "3  data/train/11783370.jpg  data/images/11783370.jpg  \n",
       "4  data/train/11782469.jpg  data/images/11782469.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_df = pd.read_csv(TRN_CSV, index_col='subject_id').reset_index()\n",
    "val_df = pd.read_csv(VAL_CSV, index_col='subject_id').reset_index()\n",
    "\n",
    "trn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = [T.ToTensor()]\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "        transforms.append(T.RandomVerticalFlip(0.5))\n",
    "        transforms.append(T.RandomRotate())\n",
    "        transforms.append(T.ColorJitter(\n",
    "            brightness=0.25, contrast=0.25, saturation=0.25, hue=0.25))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = LabelBabelDataset(trn_df, get_transform(train=True))\n",
    "val_dataset = LabelBabelDataset(val_df, get_transform(train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_loader = torch.utils.data.DataLoader(\n",
    "    trn_dataset, batch_size=1, shuffle=True, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=1, shuffle=False, num_workers=4,\n",
    "    collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(DEVICE)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/models/checkpoint_005.pth.tar')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_checkpoint = sorted(MODEL_DIR.glob(CHECKPOINT.format('*')))[-1]\n",
    "\n",
    "state = torch.load(last_checkpoint)\n",
    "\n",
    "first_epoch = state['epoch']\n",
    "model.load_state_dict(state['state_dict'])\n",
    "optimizer.load_state_dict(state['optimizer'])\n",
    "\n",
    "last_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_state(epoch, model, optimizer):\n",
    "    state_path = MODEL_DIR / CHECKPOINT.format(str(epoch).zfill(3))\n",
    "    if state_path.exists():\n",
    "        return\n",
    "    state = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(state, state_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    for epoch in range(first_epoch, EPOCHS):\n",
    "        train_one_epoch(\n",
    "            model, optimizer, trn_loader, DEVICE, epoch, print_freq=100)\n",
    "        lr_scheduler.step()\n",
    "        evaluate(model, val_loader, device=DEVICE)\n",
    "        if state % 10 == 0:\n",
    "            save_state(epoch, model, optimizer)\n",
    "\n",
    "    save_state(epoch, model, optimizer)\n",
    "\n",
    "\n",
    "# train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
